{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of Copy of Quiz 5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryamaan23/ML-TOOLBOX/blob/master/Copy_of_Copy_of_Copy_of_Copy_of_Quiz_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1y00BqjpyTP",
        "colab_type": "text"
      },
      "source": [
        "##1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YWHjWjtp9Bz",
        "colab_type": "text"
      },
      "source": [
        "###Q. Generate Random points\n",
        "Write a function that takes parameters $r_1$, $r_2$, $n$ and generates random points $(x_1, x_2)$ as follows - \n",
        "- $n$ random points that lie within a circle with center at $(0, 0)$ and radius $r_1$ $\\rightarrow$ These points belong to class ```'inner'```\n",
        "- $n$ random points that lie outside circle with center at $(0, 0)$ and radius $r_1$ but inside circle with center at $(0, 0)$ and radius $r_2$ $\\rightarrow$ These points belong to class ```'outer'```\n",
        "\n",
        "The function gen_random should return $X$, $Cls$ :\n",
        "- $X$ is a numpy array of shape $(2n, 2)$ which has the $2n$ random points generated as above\n",
        "- $Cls$ is a numpy array of shape $(2n,)$ which contains the value of the class corresponding to each point in $X$ (values will be either ```'inner'``` or ```'outer'```)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WWEUIetpA04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random as rand\n",
        "def gen_random_points(r1, r2, n):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    r1 : float\n",
        "    r2 : float\n",
        "    n : int, number of points\n",
        "  Outputs:\n",
        "    X : numpy array, shape -> (2n, 2)\n",
        "    Cls : numpy array, shape -> (2n, )\n",
        "  \"\"\"\n",
        "  ns=np.random.rand(n)*r1\n",
        "  thetas=np.random.rand(n)*2*np.pi\n",
        "  x1_s=rs*np.cos(thetas)\n",
        "  x2_s=rs*np.sin(thetas)\n",
        "\n",
        "  rs_outer=np.random.rand(n)*(r2-r1)+r1\n",
        "  thetas_outer=np.random.rand(n)*2*np.pi\n",
        "  x_1s_outer=rs_outer*np.cos(thetas_outer)\n",
        "  x_2s_outer=rs_outer*np.sin(thetas_outer)\n",
        "\n",
        "  X_inner=np.hstack([x_1s.reshape(n,1),x_2s.reshape(n,1)])\n",
        "  X_outer=np.hstack([x_1s_outer.reshape(n,1),x_2s_outer.reshape(n,1)])\n",
        "  X=np.vstack([X_inner,X_outer])\n",
        "  Cls=np.array(['inner']*n+['outer']*n)\n",
        "  return (X,Cls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQEovtnWvF1E",
        "colab_type": "text"
      },
      "source": [
        "##2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZnBaClDvJbp",
        "colab_type": "text"
      },
      "source": [
        "###Q. One-hot encode\n",
        "Write a function that takes a numpy array $Cls$ of shape $(n, )$ which contains class labels of $n$ samples of data and creates a numpy array, $Y_d$ of shape $(n, \\text{unique})$ containing 1-hot representations of the $n$ samples. Here $\\text{unique}$ is the number of unique classes in $Cls$. <br>\n",
        "The function should return two values - \n",
        "- $Y_d$ - numpy array of shape $(n, \\text{unique})$ with 1-hot representations\n",
        "- ```cls_order``` - numpy array of shape $(\\text{unique}, )$ which contains the labels of the classes in the order in which they occur in the 1-hot representation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLB75bffvIne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def one_hot_encode(Cls):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    Cls: numpy array, shape: (n, ) contains class labels of n data samples\n",
        "  Outputs:\n",
        "    Yd : numpy array of shape (n, unique)\n",
        "    cls_order: numpy array of shape(unique, )\n",
        "  \"\"\"\n",
        "  ### Write your code here\n",
        "  unique_classes=np.unique(Cls)\n",
        "  n=Cls.shape[0]\n",
        "  N=unique_classes.shape[0]\n",
        "  class_dict={}\n",
        "  for i in range(N):\n",
        "    class_dict[unique_classes[i]]=i\n",
        "\n",
        "  Yd=np.zeros((n,N))\n",
        "  for i in range(n):\n",
        "    Yd[i,class_dict[Cls[i]]]=1\n",
        "  return Yd,unique_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPi2saBHn4yn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "836661e8-a8e7-4fd8-d8c4-bc4a50229aba"
      },
      "source": [
        "Cls=np.array(['cat','dog','cat','cat','dog'])\n",
        "one_hot_encode(Cls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.]]), array(['cat', 'dog'], dtype='<U3'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFD0WNUbzYUo",
        "colab_type": "text"
      },
      "source": [
        "##3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTczqgGRzZ-K",
        "colab_type": "text"
      },
      "source": [
        "###Q. Softmax\n",
        "Write a function that takes a vector (numpy array of shape $(f,)$) - $(y_{in})$ and returns the result vector (numpy array of shape $(f,)$) - $(y_{out})$ of applying the softmax non-linearity to it. <br>\n",
        "$$\n",
        "y_{out}^{i} = \\frac{e^{y_{in}^{i}}}{\\sum_{i=1}^{f}e^{y_{in}^{i}}}\n",
        "$$ \n",
        "\n",
        "where $y^{i}$ refers to the $i^{th}$ component of vector $y$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6jF41px0EAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax1(y_in):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    y_in : numpy array of shape (f, ), input vector \n",
        "  Outputs:\n",
        "    y_out : numpy array of shape(f, ), output vector\n",
        "  \"\"\"\n",
        "  ### Write your code here\n",
        "  e_y_in=(np.e)**y_in\n",
        "  y_out=e_y_in/np.sum(e_y_in)\n",
        "  return y_out\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JD-rqkTpcIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30788652-f3bf-437e-f99c-c8382d51377c"
      },
      "source": [
        "a=np.array([1,2,3])\n",
        "2**a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 4, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bymfyiNKzoep",
        "colab_type": "text"
      },
      "source": [
        "##4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgvyBiO2zttQ",
        "colab_type": "text"
      },
      "source": [
        "###Q. Standardize\n",
        "Write a function that takes input dataset $X$ of shape $(n, f)$ and returns dataset $X_{stdz}$  after standardizing $X$ where\n",
        "$$\n",
        "  X_{stdz}^i = \\frac{X^i - \\mu(X)}{\\sigma(X)}\n",
        "$$\n",
        "where $\\mu(X)$ is the feature-wise mean of all samples in $X$ and $\\sigma(X)$ is feature-wise standard deviation of all samples in $X$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wLIHeN-3G1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def standardize(X):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    X: numpy array of shape (n, f)\n",
        "  Outputs:\n",
        "    X_stdz : numpy array of shape (n, f)\n",
        "  \"\"\"\n",
        "  mu_X=np.mean(X,axis=0)\n",
        "  sigma_X=np.std(X,axis=0)\n",
        "  X_stdz=(X-mu_X)/(sigma_x+10**-8)\n",
        "  return X_stdz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kazu6ZCf7xVU",
        "colab_type": "text"
      },
      "source": [
        "##5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oPGUWp37y63",
        "colab_type": "text"
      },
      "source": [
        "###Q. Normalize\n",
        "Write a function that takes input dataset $X$ of shape $(n, f)$ and returns dataset $X_{normd}$  after normalizing $X$ where\n",
        "$$\n",
        "  X_{normd}^i = \\frac{X^i - \\min(X)}{max(X) - min(X)}\n",
        "$$\n",
        "where $\\max(X)$ is the feature-wise maximum of all samples in $X$ and $min(X)$ is feature-wise minimum of all samples in $X$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC3cuVxU-vSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "def normalize(X):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    X: numpy array of shape (n, f)\n",
        "  Outputs:\n",
        "    X_normd : numpy array of shape (n, f)\n",
        "  \"\"\"\n",
        "  ### Write your code here\n",
        "  min_max_scaler=preprocessing.MinMaxScaler()\n",
        "  X_min_max=min_max_scaler.fit_transform(X)\n",
        "  return X_min_max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWzw6prouJLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0664eb31-2546-47ea-e28b-5d2df678e5c4"
      },
      "source": [
        "X=np.array([[1,-1,2],\n",
        "           [2,0,0],\n",
        "           [0,1,-1]])\n",
        "normalize(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5       , 0.        , 1.        ],\n",
              "       [1.        , 0.5       , 0.33333333],\n",
              "       [0.        , 1.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}